{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Жанровая классификация аудио"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import torch\n",
    "import torchsummary as ts\n",
    "import keras\n",
    "\n",
    "import json\n",
    "\n",
    "from functools import reduce\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from keras.backend import clear_session\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, CSVLogger, BackupAndRestore\n",
    "\n",
    "from utils import label2vec\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.config.list_physical_devices())\n",
    "print(f'MPS is available: {torch.backends.mps.is_available()}')\n",
    "print(f'MPS is built: {torch.backends.mps.is_built()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фильтрация метаданных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data/fma_small'\n",
    "METADATA_DIR = './data/fma_metadata/'\n",
    "\n",
    "mp3_files = glob.glob(DATA_DIR + '/*/*.mp3')\n",
    "mp3_names = list(map(lambda f: np.int64(f.split('/')[-1].split('.')[0]), mp3_files))\n",
    "\n",
    "raw_tracks = pd.read_csv(METADATA_DIR + 'raw_tracks.csv')\n",
    "tracks = raw_tracks[raw_tracks['track_id'].isin(mp3_names)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сбор признаков, полученных с помощью `librosa`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.read_csv(METADATA_DIR + 'features.csv', index_col=0, header=[0, 1, 2])\n",
    "features_df = features_df[features_df.index.isin(mp3_names)]\n",
    "\n",
    "features = np.unique(list(map(lambda x: x[0], list(features_df.columns))))\n",
    "\n",
    "print(f\"Features available: {features}\")\n",
    "print(f\"Total: {len(features)}\")\n",
    "\n",
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Отбор признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим всю имеющуюся информацию о треках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим число непустых значений тегов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks['tags'].map(lambda x: None if x == '[]' else x).notnull().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчитаем число уникальных тегов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tags = reduce(lambda tags, l: tags.union(eval(l)), tracks['tags'], set())\n",
    "print(len(unique_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оставим предположительно полезную информацию из набора данных. Убедимся\n",
    "в её необходимости позже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep = [\n",
    "  'track_id', \"album_id\", \"artist_id\", \"track_duration\", \n",
    "  \"track_genres\", \"track_instrumental\", \"track_interest\", \"track_listens\",\n",
    "]\n",
    "\n",
    "filtered_tracks = tracks[to_keep]\n",
    "filtered_tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем время в секунды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duration_to_int(t):\n",
    "  splitted = t.split(\":\")\n",
    "  \n",
    "  return int(splitted[0]) * 60 + int(splitted[1])\n",
    "\n",
    "filtered_tracks.loc[:,'track_duration'] = filtered_tracks.track_duration.apply(duration_to_int)\n",
    "filtered_tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Узнаем количество жанров для треков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = filtered_tracks['track_genres'].map(lambda x: json.loads(x.replace(\"'\", \"\\\"\")))\n",
    "genre_ids = genres.map(lambda x: list(map(lambda y: y['genre_id'], x)))\n",
    "genre_ids.map(lambda x: len(x)).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим базовые жанры для каждого трека"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genres = pd.read_csv(METADATA_DIR + 'genres.csv')\n",
    "\n",
    "base_genres = genre_ids.map(lambda x: all_genres[all_genres.genre_id == int(x[0])].iloc[0].top_level)\n",
    "\n",
    "filtered_tracks['track_genres'] = base_genres\n",
    "filtered_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_genres.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили 8 сбалансированных классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_corr(df):\n",
    "  corr = df.corr()\n",
    "  cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "  mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "  sns.heatmap(corr, mask=mask, cmap=cmap)\n",
    "  \n",
    "display_corr(filtered_tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Жанр трека очень плохо коррелирует с его длительностью, поэтому исключим\n",
    "этот признак из рассмотрения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tracks = filtered_tracks.drop('track_duration', axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавим значения, предпосчитанные с помощью `librosa`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = features_df.merge(filtered_tracks, how='inner', on='track_id')\n",
    "\n",
    "display_corr(merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конечно, признаков слишком много. Из всех возьмем признаки с наибольшей по\n",
    "модулю корреляцией.\n",
    "\n",
    "Для этого отсортируем признаки по степени корреляции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = merged.corr()\n",
    "\n",
    "genres_corr = correlation['track_genres'].sort_values(key=lambda x: np.abs(x), ascending=False)\n",
    "genres_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изобразим распределение значений корреляции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(genres_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что наибольшее число признаков имеют почти нулевую корреляцию.\n",
    "В связи с этим выберем наиболее информативные из них"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary = 0.2\n",
    "\n",
    "selected = merged[genres_corr[abs(genres_corr) > boundary].reset_index()['index']]\n",
    "selected.set_index('track_id', inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме того, удалим сильно коррелирующие друг с другом нецелевые признаки,\n",
    "оставив среди таких пар те, что больше коррелируют с целевым"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = selected.corr()\n",
    "\n",
    "to_be_excluded = set()\n",
    "\n",
    "boundary = 0.9\n",
    "\n",
    "for i in c:\n",
    "  for j in c:\n",
    "    if abs(c[i][j]) > boundary and i != j and i != 'track_genres' and j != 'track_genres':\n",
    "      least_informative = i if c['track_genres'][i] < c['track_genres'][j] else j\n",
    "      to_be_excluded.add(least_informative)\n",
    "      \n",
    "to_be_excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = selected.drop(to_be_excluded, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перекодируем метки классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_le = LabelEncoder()\n",
    "\n",
    "selected.track_genres = genre_le.fit_transform(selected.track_genres)\n",
    "selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected.columns = selected.columns.map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in selected.columns:\n",
    "  if column == 'track_genres':\n",
    "    continue\n",
    "  selected[column] = StandardScaler().fit_transform(selected[column].to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Убедимся, что `StandardScaler` отработал корректно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные по принципу `train/test/split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = selected.drop('track_genres', axis=1).to_numpy()\n",
    "y = selected['track_genres'].to_numpy()\n",
    "\n",
    "test_size = 0.2\n",
    "valid_size = 0.1\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(x, y, test_size=0.2, random_state=69, stratify=y)\n",
    "    \n",
    "X_train, X_valid, y_train, y_valid = \\\n",
    "    train_test_split(X_train, y_train, test_size=valid_size / (1 - test_size),\n",
    "                     random_state=69, stratify=y_train)\n",
    "    \n",
    "n_classes = np.max(y) + 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сравнение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = np.max(y) + 1\n",
    "list_of_neighbours = list(map(int, range(1, 300, 5)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опишем функцию, которая будет отображать результаты экспериментов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_score(n, scores, names):\n",
    "    d = {names: n, 'score': scores}\n",
    "    df = pd.DataFrame(d)\n",
    "\n",
    "    sns.set(style='darkgrid')\n",
    "    sns.lineplot(x=names, y='score', data=df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычислим значения `accuracy` для моделей с разным числом соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_n = -1\n",
    "best_score = -1\n",
    "scores = []\n",
    "for n in tqdm(list_of_neighbours):\n",
    "    knn = KNeighborsClassifier(p=1, n_neighbors=n)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    score = knn.score(X_test, y_test)\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_n = n\n",
    "    scores.append(score)\n",
    "\n",
    "plot_score(list_of_neighbours, scores, 'neighbors')\n",
    "print(f'Лучшая модель: {best_n} соседей, точность: {best_score}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конечно, такой метод оценки качества модели не является надежным, лучше воспользоваться\n",
    "оценкой методом кросс-валидации — `cross_val_score`.\n",
    "\n",
    "В дальнейшем будем использовать именно этот метод."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_n = -1\n",
    "best_score = -1\n",
    "scores = []\n",
    "\n",
    "for n in tqdm(list_of_neighbours):\n",
    "    knn = KNeighborsClassifier(p=2, n_neighbors=n)\n",
    "    \n",
    "    score = cross_val_score(knn, x, y, cv=5).mean()\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_n = n\n",
    "    scores.append(score)\n",
    "\n",
    "plot_score(list_of_neighbours, scores, 'neighbors')\n",
    "print(f'Лучшая модель: {best_n} соседей, точность: {best_score}')\n",
    "\n",
    "models.append((KNeighborsClassifier(p=2, n_neighbors=best_n), 'sklearn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for n in tqdm(list_of_neighbours):\n",
    "    knn = KNeighborsClassifier(p=2, n_neighbors=n)\n",
    "    knn.fit(X_train, y_train)\n",
    "    probs = knn.predict_proba(X_test)\n",
    "    \n",
    "    loss = log_loss(y_test, probs)\n",
    "    scores.append(loss)\n",
    "\n",
    "plot_score(list_of_neighbours, scores, 'neighbors')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C-svc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### форма функции решения: one vs one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "\n",
    "scores = []\n",
    "ps = list(map(int, range(1, 10, 1)))\n",
    "for p in tqdm(ps):\n",
    "    svc = svm.SVC(degree=p, decision_function_shape='ovo')\n",
    "    svc.fit(X_train, y_train)\n",
    "    scores.append(svc.score(X_test, y_test))\n",
    "\n",
    "plot_score(ps, scores, 'degree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "Cs = list(map(int, range(1, 100, 1)))\n",
    "\n",
    "for c in tqdm(Cs):\n",
    "    svc = svm.SVC(C=c, decision_function_shape='ovo')\n",
    "    svc.fit(X_train, y_train)\n",
    "    scores.append(svc.score(X_test, y_test))\n",
    "\n",
    "plot_score(Cs, scores, 'C-argument')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores =[]\n",
    "for c in tqdm(Cs):\n",
    "    svc = svm.SVC(C=c, decision_function_shape='ovo')\n",
    "    cvs = cross_val_score(svc, x, y, cv=5)\n",
    "    scores.append(cvs.mean())\n",
    "\n",
    "plot_score(Cs, scores, 'C-argument')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "\n",
    "scores = []\n",
    "Cs = list(map(int, range(1, 100, 1)))\n",
    "\n",
    "for c in tqdm(Cs):\n",
    "    clf = OneVsOneClassifier(svm.SVC(C=c))\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores.append(clf.score(X_test, y_test))\n",
    "\n",
    "plot_score(Cs, scores, 'C-argument')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for c in tqdm(Cs):\n",
    "    clf = OneVsOneClassifier(svm.SVC(C=c))\n",
    "    cvs = cross_val_score(clf, x, y, cv=5)\n",
    "    scores.append(cvs.mean())\n",
    "plot_score(Cs, scores, 'C-argument')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### форма функции решения: one vs rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for c in tqdm(Cs):\n",
    "    svc = svm.SVC(C=c, break_ties=True)\n",
    "    svc.fit(X_train, y_train)\n",
    "    scores.append(svc.score(X_test, y_test))\n",
    "\n",
    "plot_score(Cs, scores, 'C-argument')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "\n",
    "scores = []\n",
    "for c in tqdm(Cs):\n",
    "    clf = OneVsRestClassifier(svm.SVC(C=c))\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores.append(clf.score(X_test, y_test))\n",
    "\n",
    "plot_score(Cs, scores, 'C-argument')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "Cs = list(map(int, range(1, 50, 1)))\n",
    "for c in tqdm(Cs):\n",
    "    clf = OneVsRestClassifier(svm.SVC(C=c))\n",
    "    cvs = cross_val_score(clf, x, y, cv=5)\n",
    "    scores.append(cvs.mean())\n",
    "\n",
    "plot_score(Cs, scores, 'C-argument')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\nu$-svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "Nus = np.arange(0.01, 0.5, 0.01)\n",
    "for nu in tqdm(Nus):\n",
    "    nu_svc = svm.NuSVC(nu=nu, decision_function_shape='ovo')\n",
    "    nu_svc.fit(X_train, y_train)\n",
    "    scores.append(nu_svc.score(X_test, y_test))\n",
    "\n",
    "plot_score(Nus, scores, 'Nu-argument')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нейронные сети"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Базовая модель"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем в качестве модели многослойный перцептрон, для борьбы с переобучением\n",
    "воспользуемся слоями `Dropout`. Кроме того, добавим между слоями\n",
    "нормализацию по подвыборке для того, чтобы сгладить процесс обучения.\n",
    "\n",
    "В качестве функции активации выберем `leaky_relu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dropout, Dense, BatchNormalization\n",
    "\n",
    "clear_session()\n",
    "\n",
    "lr = 0.001\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Input(X_train.shape[1]))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(.3))\n",
    "\n",
    "model.add(Dense(128, activation='leaky_relu'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32, activation='leaky_relu'))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_y_train = np.array(list(map(label2vec(n_classes), y_train)))\n",
    "nn_y_test = np.array(list(map(label2vec(n_classes), y_test)))\n",
    "nn_y_valid = np.array(list(map(label2vec(n_classes), y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = input()\n",
    "\n",
    "callbacks = [\n",
    "  TensorBoard(),\n",
    "  ModelCheckpoint(f'{run}/checkpoint/', save_best_only=True, save_weights_only=True, monitor='categorical_accuracy', verbose=1),\n",
    "  CSVLogger(\"logs.csv\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, nn_y_train, validation_data=(X_valid, nn_y_valid), epochs=200, callbacks=callbacks, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(f'{run}/checkpoint/')\n",
    "model.evaluate(X_test, nn_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append((model, 'keras'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение моделей, обученных на мета-данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in models:\n",
    "  model_type = entry[1]\n",
    "  model = entry[0]\n",
    "  if model_type == 'sklearn':\n",
    "    model.fit(X_train, y_train)\n",
    "    results = model.score(X_test, y_test)\n",
    "  else:\n",
    "    results = model.evaluate(X_test, nn_y_test)\n",
    "  print(f'Результат для {model.__class__.__name__}: {results}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сверточная нейронная сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loaders import AudioDataset\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(columns=selected.columns)\n",
    "valid = pd.DataFrame(columns=selected.columns)\n",
    "test = pd.DataFrame(columns=selected.columns)\n",
    "\n",
    "train_size = 0.8\n",
    "valid_size = 0.1\n",
    "\n",
    "for i in range(0, 8):\n",
    "  cur = selected[selected['track_genres'] == i]\n",
    "  \n",
    "  n = len(cur)\n",
    "  train = pd.concat([train, cur.iloc[:int(train_size * n)]])\n",
    "  valid = pd.concat([valid, cur.iloc[int(train_size * n):int((train_size + valid_size) * n)]])\n",
    "  test = pd.concat([test, cur.iloc[int((train_size + valid_size) * n):]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = AudioDataset(test, suffix='test',\n",
    "                            sr=44100, win_length=1380, \n",
    "                            hop_length=345, data_dir=DATA_DIR)\n",
    "val_dataset = AudioDataset(valid, suffix='val',\n",
    "                           sr=44100, win_length=1380, \n",
    "                           hop_length=345, data_dir=DATA_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AudioDataset(train, suffix='train', \n",
    "                             sr=44100, win_length=1380, \n",
    "                             hop_length=345, data_dir=DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "\n",
    "model = resnet18()\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "torch.manual_seed(69)\n",
    "\n",
    "for param in model.parameters():\n",
    "  param.requires_grad = False\n",
    "  \n",
    "model.fc = torch.nn.Sequential(\n",
    "  torch.nn.Dropout(p=0.2, inplace=True),\n",
    "  torch.nn.Linear(in_features=512,\n",
    "                  out_features=256,\n",
    "                  bias=True),\n",
    "  torch.nn.Dropout(p=0.2, inplace=True),\n",
    "  torch.nn.Linear(in_features=256,\n",
    "                  out_features=8,\n",
    "                  bias=True))\n",
    "\n",
    "ts.summary(model, (3, 640, 480))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import save_state, plot_csv, restore_state\n",
    "\n",
    "model, init_epoch, best_loss, losses = restore_state(model, 'checkpoint/checkpoint.pt')\n",
    "model.to(device)\n",
    "crit = torch.nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "model.train()\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "n_batches = len(train_loader)\n",
    "\n",
    "for epoch in range(init_epoch, epochs):\n",
    "  print(f'Epoch {epoch + 1}/{epochs}')\n",
    "  pbar = tf.keras.utils.Progbar(target=n_batches)\n",
    "  \n",
    "  correct = 0\n",
    "  samples = 0\n",
    "  for i, (inputs, targets) in enumerate(train_loader):\n",
    "    inputs = inputs.to(device)\n",
    "    \n",
    "    targets = targets.argmax(dim=1)\n",
    "    targets = targets.to(device)\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    train_loss = crit(outputs, targets)\n",
    "    train_loss.backward()\n",
    "    \n",
    "    correct += int(torch.sum(outputs.argmax(dim=1) == targets))\n",
    "    samples += len(targets)\n",
    "    \n",
    "    opt.step()\n",
    "    pbar.update(i, values=[(\"loss\", train_loss.item()), (\"acc\", correct / samples)])\n",
    "    train_loader.dataset.unload()\n",
    "      \n",
    "  model.eval()\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    correct = 0\n",
    "    samples = 0\n",
    "    for inputs, targets in val_loader:\n",
    "      inputs = inputs.to(device)\n",
    "      \n",
    "      targets = targets.argmax(dim=1)\n",
    "      targets = targets.to(device)\n",
    "      \n",
    "      outputs = model(inputs)\n",
    "      val_loss = crit(outputs, targets)\n",
    "      \n",
    "      correct += int(torch.sum(outputs.argmax(dim=1) == targets))\n",
    "      samples += len(targets)\n",
    "      \n",
    "  \n",
    "  losses['epoch'].append(epoch)\n",
    "  losses['loss_type'].append('train')\n",
    "  losses['loss'].append(train_loss.item())\n",
    "  \n",
    "  losses['epoch'].append(epoch)\n",
    "  losses['loss_type'].append('val')\n",
    "  losses['loss'].append(val_loss.item())\n",
    "  \n",
    "  save_state(model, epoch, losses, best_loss)\n",
    "   \n",
    "  if val_loss.item() < best_loss:\n",
    "    best_loss = val_loss.item()\n",
    "    torch.save(model.state_dict(), 'best.pt')\n",
    "  \n",
    "  plot_csv('checkpoint/losses.csv')\n",
    "      \n",
    "  pbar.update(n_batches, values=[(\"val_loss\", val_loss.item()), (\"val_acc\", correct / samples)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=losses, x='epoch', y='loss', hue='loss_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.load('best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "e64c9a8690db34c99b15a1f7c3e93a32cbaa4232add629869dab3afba3bd6272"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
