{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Жанровая классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фильтрация метаданных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "\n",
    "DATA_DIR = './data/fma_small'\n",
    "METADATA_DIR = './data/fma_metadata/'\n",
    "\n",
    "mp3_files = glob.glob(DATA_DIR + '/*/*.mp3')\n",
    "mp3_names = list(map(lambda f: np.int64(f.split('/')[-1].split('.')[0]), mp3_files))\n",
    "\n",
    "raw_tracks = pd.read_csv(METADATA_DIR + 'raw_tracks.csv')\n",
    "tracks = raw_tracks[raw_tracks['track_id'].isin(mp3_names)]\n",
    "\n",
    "tracks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сбор признаков, полученных с помощью `librosa`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.read_csv(METADATA_DIR + 'features.csv', index_col=0, header=[0, 1, 2])\n",
    "features_df = features_df[features_df.index.isin(mp3_names)]\n",
    "\n",
    "features = np.unique(list(map(lambda x: x[0], list(features_df.columns))))\n",
    "\n",
    "print(f\"Features available: {features}\")\n",
    "print(f\"Total: {len(features)}\")\n",
    "\n",
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Отбор признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим всю имеющуюся информацию о треках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим число непустых значений тегов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks['tags'].map(lambda x: None if x == '[]' else x).notnull().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчитаем число уникальных тегов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "\n",
    "unique_tags = reduce(lambda tags, l: tags.union(eval(l)), tracks['tags'], set())\n",
    "print(len(unique_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оставим предположительно полезную информацию из набора данных. Убедимся\n",
    "в её необходимости позже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep = [\n",
    "  'track_id', \"album_id\", \"artist_id\", \"track_duration\", \n",
    "  \"track_genres\", \"track_instrumental\", \"track_interest\", \"track_listens\",\n",
    "]\n",
    "\n",
    "filtered_tracks = tracks[to_keep]\n",
    "filtered_tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем время в секунды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duration_to_int(t):\n",
    "  splitted = t.split(\":\")\n",
    "  \n",
    "  return int(splitted[0]) * 60 + int(splitted[1])\n",
    "\n",
    "filtered_tracks.loc[:,'track_duration'] = filtered_tracks.track_duration.apply(duration_to_int)\n",
    "filtered_tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Узнаем количество жанров для треков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "genres = filtered_tracks['track_genres'].map(lambda x: json.loads(x.replace(\"'\", \"\\\"\")))\n",
    "genre_ids = genres.map(lambda x: list(map(lambda y: y['genre_id'], x)))\n",
    "genre_ids.map(lambda x: len(x)).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим базовые жанры для каждого трека"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genres = pd.read_csv(METADATA_DIR + 'genres.csv')\n",
    "\n",
    "base_genres = genre_ids.map(lambda x: all_genres[all_genres.genre_id == int(x[0])].iloc[0].top_level)\n",
    "\n",
    "filtered_tracks['track_genres'] = base_genres\n",
    "filtered_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_genres.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили 8 сбалансированных классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def display_corr(df):\n",
    "  corr = df.corr()\n",
    "  cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "  mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "  sns.heatmap(corr, mask=mask, cmap=cmap)\n",
    "  \n",
    "display_corr(filtered_tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Жанр трека очень плохо коррелирует с его длительностью, поэтому исключим\n",
    "этот признак из рассмотрения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tracks = filtered_tracks.drop('track_duration', axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавим значения, предпосчитанные с помощью `librosa`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = features_df.merge(filtered_tracks, how='inner', on='track_id')\n",
    "\n",
    "display_corr(merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конечно, признаков слишком много. Из всех возьмем признаки с наибольшей по\n",
    "модулю корреляцией.\n",
    "\n",
    "Для этого отсортируем признаки по степени корреляции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = merged.corr()\n",
    "\n",
    "genres_corr = correlation['track_genres'].sort_values(key=lambda x: np.abs(x), ascending=False)\n",
    "genres_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изобразим распределение значений корреляции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(genres_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что наибольшее число признаков имеют почти нулевую корреляцию.\n",
    "В связи с этим выберем наиболее информативные из них"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary = 0.2\n",
    "\n",
    "selected = merged[genres_corr[abs(genres_corr) > boundary].reset_index()['index']]\n",
    "selected.set_index('track_id', inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме того, удалим сильно коррелирующие друг с другом нецелевые признаки,\n",
    "оставив среди таких пар те, что больше коррелируют с целевым"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = selected.corr()\n",
    "\n",
    "to_be_excluded = set()\n",
    "\n",
    "boundary = 0.9\n",
    "\n",
    "for i in c:\n",
    "  for j in c:\n",
    "    if abs(c[i][j]) > boundary and i != j and i != 'track_genres' and j != 'track_genres':\n",
    "      least_informative = i if c['track_genres'][i] < c['track_genres'][j] else j\n",
    "      to_be_excluded.add(least_informative)\n",
    "      \n",
    "to_be_excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in to_be_excluded:\n",
    "  selected.drop(feature, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перекодируем метки классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "genre_le = LabelEncoder()\n",
    "\n",
    "selected.track_genres = genre_le.fit_transform(selected.track_genres)\n",
    "selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected.columns = selected.columns.map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "for column in selected.columns:\n",
    "  if column == 'track_genres':\n",
    "    continue\n",
    "  selected[column] = StandardScaler().fit_transform(selected[column].to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Убедимся, что `StandardScaler` отработал корректно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные по принципу `train/test/split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = selected.drop('track_genres', axis=1).to_numpy()\n",
    "y = selected['track_genres'].to_numpy()\n",
    "\n",
    "test_size = 0.2\n",
    "valid_size = 0.1\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "    \n",
    "X_train, X_valid, y_train, y_valid = \\\n",
    "    train_test_split(X_train, y_train, test_size=valid_size / (1 - test_size),\n",
    "                     random_state=69)\n",
    "    \n",
    "n_classes = np.max(y) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label2vec(n_classes):\n",
    "  def inner(label):  \n",
    "    v = np.zeros(n_classes)\n",
    "    v[label - 1] = 1\n",
    "    return v\n",
    "  return inner"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сравнение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = np.max(y) + 1\n",
    "list_of_neighbours = list(map(int, range(1, 300, 5)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опишем функцию, которая будет отображать результаты экспериментов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def plot_score(n, scores, names):\n",
    "    d = {names: n, 'score': scores}\n",
    "    df = pd.DataFrame(d)\n",
    "\n",
    "    sns.set(style='darkgrid')\n",
    "    sns.lineplot(x=names, y='score', data=df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычислим значения `accuracy` для моделей с разным числом соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "best_n = -1\n",
    "best_score = -1\n",
    "scores = []\n",
    "for n in tqdm(list_of_neighbours):\n",
    "    knn = KNeighborsClassifier(p=1, n_neighbors=n)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    score = knn.score(X_test, y_test)\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_n = n\n",
    "    scores.append(score)\n",
    "\n",
    "plot_score(list_of_neighbours, scores, 'neighbors')\n",
    "print(f'Лучшая модель: {best_n} соседей, точность: {best_score}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конечно, такой метод оценки качества модели не является надежным, лучше воспользоваться\n",
    "оценкой методом кросс-валидации — `cross_val_score`.\n",
    "\n",
    "В дальнейшем будем использовать именно этот метод."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "best_n = -1\n",
    "best_score = -1\n",
    "scores = []\n",
    "for n in tqdm(list_of_neighbours):\n",
    "    knn = KNeighborsClassifier(p=2, n_neighbors=n)\n",
    "    \n",
    "    score = cross_val_score(knn, x, y, cv=5).mean()\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_n = n\n",
    "    scores.append(score)\n",
    "\n",
    "plot_score(list_of_neighbours, scores, 'neighbors')\n",
    "print(f'Лучшая модель: {best_n} соседей, точность: {best_score}')\n",
    "\n",
    "models.append((KNeighborsClassifier(p=2, n_neighbors=best_n), 'sklearn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "scores = []\n",
    "for n in tqdm(list_of_neighbours):\n",
    "    knn = KNeighborsClassifier(p=2, n_neighbors=n)\n",
    "    knn.fit(X_train, y_train)\n",
    "    probs = knn.predict_proba(X_test)\n",
    "    \n",
    "    loss = log_loss(y_test, probs)\n",
    "    scores.append(loss)\n",
    "\n",
    "plot_score(list_of_neighbours, scores, 'neighbors')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C-svc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### форма функции решения: one vs one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "\n",
    "scores = []\n",
    "ps = list(map(int, range(1, 10, 1)))\n",
    "for p in tqdm(ps):\n",
    "    svc = svm.SVC(degree=p, decision_function_shape='ovo')\n",
    "    svc.fit(X_train, y_train)\n",
    "    scores.append(svc.score(X_test, y_test))\n",
    "\n",
    "plot_score(ps, scores, 'degree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "Cs = list(map(int, range(1, 100, 1)))\n",
    "\n",
    "for c in tqdm(Cs):\n",
    "    svc = svm.SVC(C=c, decision_function_shape='ovo')\n",
    "    svc.fit(X_train, y_train)\n",
    "    scores.append(svc.score(X_test, y_test))\n",
    "\n",
    "plot_score(Cs, scores, 'C-argument')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores =[]\n",
    "for c in tqdm(Cs):\n",
    "    svc = svm.SVC(C=c, decision_function_shape='ovo')\n",
    "    cvs = cross_val_score(svc, x, y, cv=5)\n",
    "    scores.append(cvs.mean())\n",
    "\n",
    "plot_score(Cs, scores, 'C-argument')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "\n",
    "scores = []\n",
    "Cs = list(map(int, range(1, 100, 1)))\n",
    "\n",
    "for c in tqdm(Cs):\n",
    "    clf = OneVsOneClassifier(svm.SVC(C=c))\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores.append(clf.score(X_test, y_test))\n",
    "\n",
    "plot_score(Cs, scores, 'C-argument')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for c in tqdm(Cs):\n",
    "    clf = OneVsOneClassifier(svm.SVC(C=c))\n",
    "    cvs = cross_val_score(clf, x, y, cv=5)\n",
    "    scores.append(cvs.mean())\n",
    "plot_score(Cs, scores, 'C-argument')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### форма функции решения: one vs rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for c in tqdm(Cs):\n",
    "    svc = svm.SVC(C=c, break_ties=True)\n",
    "    svc.fit(X_train, y_train)\n",
    "    scores.append(svc.score(X_test, y_test))\n",
    "\n",
    "plot_score(Cs, scores, 'C-argument')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "\n",
    "scores = []\n",
    "for c in tqdm(Cs):\n",
    "    clf = OneVsRestClassifier(svm.SVC(C=c))\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores.append(clf.score(X_test, y_test))\n",
    "\n",
    "plot_score(Cs, scores, 'C-argument')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "Cs = list(map(int, range(1, 50, 1)))\n",
    "for c in tqdm(Cs):\n",
    "    clf = OneVsRestClassifier(svm.SVC(C=c))\n",
    "    cvs = cross_val_score(clf, x, y, cv=5)\n",
    "    scores.append(cvs.mean())\n",
    "\n",
    "plot_score(Cs, scores, 'C-argument')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\nu$-svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "Nus = np.arange(0.01, 0.5, 0.01)\n",
    "for nu in tqdm(Nus):\n",
    "    nu_svc = svm.NuSVC(nu=nu, decision_function_shape='ovo')\n",
    "    nu_svc.fit(X_train, y_train)\n",
    "    scores.append(nu_svc.score(X_test, y_test))\n",
    "\n",
    "plot_score(Nus, scores, 'Nu-argument')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нейронные сети"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Базовая модель"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем в качестве модели многослойный перцептрон, для борьбы с переобучением\n",
    "воспользуемся слоями `Dropout`. Кроме того, добавим между слоями\n",
    "нормализацию по подвыборке для того, чтобы сгладить процесс обучения.\n",
    "\n",
    "В качестве функции активации выберем `leaky_relu` как функцию, которая в отличие\n",
    "от `relu` не приводит к т.н. Dying RELU problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dropout, Dense, BatchNormalization\n",
    "from keras.backend import clear_session\n",
    "\n",
    "clear_session()\n",
    "\n",
    "lr = 0.001\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Input(X_train.shape[1]))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(128, activation='leaky_relu'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(32, activation='leaky_relu'))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_y_train = np.array(list(map(label2vec(n_classes), y_train)))\n",
    "nn_y_test = np.array(list(map(label2vec(n_classes), y_test)))\n",
    "nn_y_valid = np.array(list(map(label2vec(n_classes), y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard, ModelCheckpoint, CSVLogger\n",
    "\n",
    "run = input()\n",
    "\n",
    "callbacks = [\n",
    "  TensorBoard(),\n",
    "  ModelCheckpoint(f'{run}/checkpoint/', save_best_only=True, save_weights_only=True, monitor='categorical_accuracy', verbose=1),\n",
    "  CSVLogger(\"logs.csv\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, nn_y_train, validation_data=(X_valid, nn_y_valid), epochs=200, callbacks=callbacks, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(f'{run}/checkpoint/')\n",
    "model.evaluate(X_test, nn_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append((model, 'probs'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение моделей, обученных на мета-данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in models:\n",
    "  model_type = entry[1]\n",
    "  model = entry[0]\n",
    "  if model_type == 'sklearn':\n",
    "    model.fit(X_train, y_train)\n",
    "    results = model.score(X_test, y_test)\n",
    "  else:\n",
    "    results = model.evaluate(X_test, nn_y_test)\n",
    "  print(f'Результат для {model.__class__.__name__}: {results}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сверточная нейронная сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_by_id(id, sr=22050):\n",
    "  id = f'{id:06}'\n",
    "  subfolder = id[:3]\n",
    "  filename = f'{DATA_DIR}/{subfolder}/{id}.mp3'\n",
    "  return librosa.load(filename, sr=sr)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from keras.utils import Sequence\n",
    "\n",
    "@dataclass\n",
    "class AudioLoader(Sequence):\n",
    "  data: pd.DataFrame\n",
    "  sr: int = 22050\n",
    "  batch_size: int = 64\n",
    "  x = None\n",
    "  y = None\n",
    "  \n",
    "  def __post_init__(self):\n",
    "    self.x = []\n",
    "    self.y = []\n",
    "    for index, row in self.data.iterrows():\n",
    "      try:\n",
    "        audio = get_audio_by_id(index)\n",
    "      except Exception as e:\n",
    "        print(f\"Skipping at {index}\")\n",
    "        \n",
    "      audio = np.pad(audio, (0, max(self.sr * 32 - audio.shape[0], 0)))\n",
    "      \n",
    "      spec = librosa.feature.melspectrogram(y=audio)\n",
    "      self.x.append(spec.reshape(spec.shape[0], spec.shape[1], 1))\n",
    "      self.y.append(label2vec(8)(int(row['track_genres'])))\n",
    "    \n",
    "    self.x = np.array(self.x)\n",
    "    self.y = np.array(self.y)\n",
    "    \n",
    "    \n",
    "  def __len__(self):\n",
    "    return self.data.shape[0] // self.batch_size\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "    \n",
    "    x_cur =  x[self.batch_size * index:(self.batch_size + 1) * index]\n",
    "    y_cur =  y[self.batch_size * index:(self.batch_size + 1) * index]\n",
    "    \n",
    "    return x_cur, y_cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(selected, test_size=0.2, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = AudioLoader(train)\n",
    "val_loader = AudioLoader(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch = train_loader[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense\n",
    "import keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (32, 32), strides=(32, 32), activation='relu', input_shape=first_batch.shape[1:]))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(32, (8, 8), strides=(8, 8), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "  ModelCheckpoint(monitor='val_accuracy', save_best_only=True, save_weights_only=True),\n",
    "  CSVLogger(),\n",
    "  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_loader, validation_data=val_loader, batch_size=128, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e64c9a8690db34c99b15a1f7c3e93a32cbaa4232add629869dab3afba3bd6272"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
