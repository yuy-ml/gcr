{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Жанровая классификация аудио"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "\n",
    "import torch\n",
    "import torch.mps\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import torchsummary as ts\n",
    "\n",
    "from functools import reduce\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.metrics import log_loss\n",
    "from scipy.optimize import minimize_scalar\n",
    "from keras.backend import clear_session\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, CSVLogger, BackupAndRestore\n",
    "\n",
    "from utils import label2vec\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, что GPU доступно для вычислений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.config.list_physical_devices())\n",
    "print(f'MPS is available: {torch.backends.mps.is_available()}')\n",
    "print(f'MPS is built: {torch.backends.mps.is_built()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фильтрация метаданных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data/fma_small'\n",
    "METADATA_DIR = './data/fma_metadata/'\n",
    "\n",
    "mp3_files = glob.glob(DATA_DIR + '/*/*.mp3')\n",
    "mp3_names = list(map(lambda f: np.int64(f.split('/')[-1].split('.')[0]), mp3_files))\n",
    "\n",
    "raw_tracks = pd.read_csv(METADATA_DIR + 'raw_tracks.csv')\n",
    "tracks = raw_tracks[raw_tracks['track_id'].isin(mp3_names)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сбор признаков, полученных с помощью `librosa`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве метаданных для аудио будем использовать уже собранный набор данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.read_csv(METADATA_DIR + 'features.csv', index_col=0, header=[0, 1, 2])\n",
    "features_df = features_df[features_df.index.isin(mp3_names)]\n",
    "\n",
    "features = np.unique(list(map(lambda x: x[0], list(features_df.columns))))\n",
    "\n",
    "print(f\"Features available: {features}\")\n",
    "print(f\"Total: {len(features)}\")\n",
    "\n",
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Отбор признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим всю имеющуюся информацию о треках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tracks.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим число непустых значений тегов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks['tags'].map(lambda x: None if x == '[]' else x).notnull().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчитаем число уникальных тегов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tags = reduce(lambda tags, l: tags.union(eval(l)), tracks['tags'], set())\n",
    "print(len(unique_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оставим предположительно полезную информацию из набора данных. Убедимся\n",
    "в её необходимости позже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep = [\n",
    "  'track_id', \"album_id\", \"artist_id\", \"track_duration\", \n",
    "  \"track_genres\", \"track_instrumental\", \"track_interest\", \"track_listens\",\n",
    "]\n",
    "\n",
    "filtered_tracks = tracks[to_keep]\n",
    "filtered_tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем время в секунды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duration_to_int(t):\n",
    "  splitted = t.split(\":\")\n",
    "  \n",
    "  return int(splitted[0]) * 60 + int(splitted[1])\n",
    "\n",
    "filtered_tracks.loc[:,'track_duration'] = filtered_tracks.track_duration.apply(duration_to_int)\n",
    "filtered_tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Узнаем количество жанров для треков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = filtered_tracks['track_genres'].map(lambda x: json.loads(x.replace(\"'\", \"\\\"\")))\n",
    "genre_ids = genres.map(lambda x: list(map(lambda y: y['genre_id'], x)))\n",
    "genre_ids.map(lambda x: len(x)).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим базовые жанры для каждого трека"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genres = pd.read_csv(METADATA_DIR + 'genres.csv')\n",
    "\n",
    "base_genres = genre_ids.map(lambda x: all_genres[all_genres.genre_id == int(x[0])].iloc[0].top_level)\n",
    "\n",
    "filtered_tracks['track_genres'] = base_genres\n",
    "filtered_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_genres.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили 8 сбалансированных классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_corr(df):\n",
    "  corr = df.corr()\n",
    "  cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "  mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "  sns.heatmap(corr, mask=mask, cmap=cmap)\n",
    "  \n",
    "display_corr(filtered_tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Жанр трека очень плохо коррелирует с его длительностью, поэтому исключим\n",
    "этот признак из рассмотрения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tracks = filtered_tracks.drop('track_duration', axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавим значения, предпосчитанные с помощью `librosa`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = features_df.merge(filtered_tracks, how='inner', on='track_id')\n",
    "\n",
    "display_corr(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конечно, признаков слишком много. Из всех возьмем признаки с наибольшей по\n",
    "модулю корреляцией.\n",
    "\n",
    "Для этого отсортируем признаки по степени корреляции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = merged.corr()\n",
    "\n",
    "genres_corr = correlation['track_genres'].sort_values(key=lambda x: np.abs(x), ascending=False)\n",
    "genres_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изобразим распределение значений корреляции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(genres_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что наибольшее число признаков имеют почти нулевую корреляцию.\n",
    "В связи с этим выберем наиболее информативные из них"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary = 0.2\n",
    "\n",
    "selected = merged[genres_corr[abs(genres_corr) > boundary].reset_index()['index']]\n",
    "selected.set_index('track_id', inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме того, удалим сильно коррелирующие друг с другом нецелевые признаки,\n",
    "оставив среди таких пар те, что больше коррелируют с целевым"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = selected.corr()\n",
    "\n",
    "to_be_excluded = set()\n",
    "\n",
    "boundary = 0.9\n",
    "\n",
    "for i in c:\n",
    "  for j in c:\n",
    "    if abs(c[i][j]) > boundary and i != j and i != 'track_genres' and j != 'track_genres':\n",
    "      least_informative = i if c['track_genres'][i] < c['track_genres'][j] else j\n",
    "      to_be_excluded.add(least_informative)\n",
    "      \n",
    "to_be_excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = selected.drop(to_be_excluded, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перекодируем метки классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_le = LabelEncoder()\n",
    "\n",
    "selected.track_genres = genre_le.fit_transform(selected.track_genres)\n",
    "selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected.columns = selected.columns.map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in selected.columns:\n",
    "  if column == 'track_genres':\n",
    "    continue\n",
    "  selected[column] = StandardScaler().fit_transform(selected[column].to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Убедимся, что `StandardScaler` отработал корректно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected.to_csv('data/selected.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные по принципу `train/test/split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = pd.read_csv('inferenced.csv', index_col='track_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = selected.drop('track_genres', axis=1).to_numpy()\n",
    "y = selected['track_genres'].to_numpy()\n",
    "\n",
    "test_size = 0.2\n",
    "valid_size = 0.1\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(x, y, test_size=0.2, random_state=69, stratify=y)\n",
    "    \n",
    "X_train, X_valid, y_train, y_valid = \\\n",
    "    train_test_split(X_train, y_train, test_size=valid_size / (1 - test_size),\n",
    "                     random_state=69, stratify=y_train)\n",
    "    \n",
    "n_classes = np.max(y) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = np.max(y) + 1\n",
    "list_of_neighbours = list(map(int, range(1, 300, 5)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опишем функцию, которая будет отображать результаты экспериментов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_score(n, scores, names):\n",
    "    d = {names: n, 'score': scores}\n",
    "    df = pd.DataFrame(d)\n",
    "\n",
    "    sns.set(style='darkgrid')\n",
    "    sns.lineplot(x=names, y='score', data=df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычислим значения `accuracy` для моделей с разным числом соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_n = -1\n",
    "best_score = -1\n",
    "scores = []\n",
    "for n in tqdm(list_of_neighbours):\n",
    "    knn = KNeighborsClassifier(p=1, n_neighbors=n)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    score = knn.score(X_test, y_test)\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_n = n\n",
    "    scores.append(score)\n",
    "\n",
    "plot_score(list_of_neighbours, scores, 'neighbors')\n",
    "print(f'Лучшая модель: {best_n} соседей, точность: {best_score}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конечно, такой метод оценки качества модели не является надежным, лучше воспользоваться\n",
    "оценкой методом кросс-валидации — `cross_val_score`.\n",
    "\n",
    "В дальнейшем будем использовать именно этот метод."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_n = -1\n",
    "best_score = -1\n",
    "scores = []\n",
    "\n",
    "for n in tqdm(list_of_neighbours):\n",
    "    knn = KNeighborsClassifier(p=2, n_neighbors=n)\n",
    "    \n",
    "    score = cross_val_score(knn, x, y, cv=5).mean()\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_n = n\n",
    "    scores.append(score)\n",
    "\n",
    "plot_score(list_of_neighbours, scores, 'neighbors')\n",
    "print(f'Лучшая модель: {best_n} соседей, точность: {best_score}')\n",
    "\n",
    "models.append((KNeighborsClassifier(p=2, n_neighbors=best_n), 'sklearn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for n in tqdm(list_of_neighbours):\n",
    "    knn = KNeighborsClassifier(p=2, n_neighbors=n)\n",
    "    knn.fit(X_train, y_train)\n",
    "    probs = knn.predict_proba(X_test)\n",
    "    \n",
    "    loss = log_loss(y_test, probs)\n",
    "    scores.append(loss)\n",
    "\n",
    "plot_score(list_of_neighbours, scores, 'neighbors')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\nu$-svc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У $\\nu$-svc есть несколько возможных для использования ядер:\n",
    "\n",
    "- linear\n",
    "- poly\n",
    "- rbf\n",
    "- sigmoid\n",
    "\n",
    "Сравним их между собой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n",
    "kernels_scores: dict[str, float] = {}\n",
    "for kernel in tqdm(kernels):\n",
    "    nu_svc = NuSVC(kernel=kernel)\n",
    "    kernels_scores[kernel] = cross_val_score(nu_svc, x, y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_score(kernels, kernels_scores.values(), 'kernels')\n",
    "\n",
    "best_kernel = max(kernels_scores, key=kernels_scores.get)\n",
    "print(f'Лучшее ядро для svc: {best_kernel} c точностью {kernels_scores[best_kernel]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для ядра _poly_ можно выбирать степень полинома. Посмотрим на точность при\n",
    "разных степенях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = range(1, 10)\n",
    "\n",
    "degrees_scores: dict[int, float] = {}\n",
    "for degree in tqdm(degrees):\n",
    "    nu_svc = NuSVC(kernel=\"poly\", degree=degree)\n",
    "    degrees_scores[degree] = cross_val_score(nu_svc, x, y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_score(degrees, degrees_scores.values(), 'degrees')\n",
    "\n",
    "best_degree = max(degrees_scores, key=degrees_scores.get)\n",
    "print(f'Для ядра poly лучшая степень: {best_degree} с точностью {degrees_scores[best_degree]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть ядро с использованием линейной функции определённо лучше полиномиальной."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим rbf в качестве ядра. Она принимает аргументом $\\nu$. Попробуем\n",
    "максимизировать `cross_val_scrore`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nu_cross_val_score(nu):\n",
    "    nu_svc = NuSVC(kernel=\"rbf\", nu=nu)\n",
    "    return -cross_val_score(nu_svc, x, y, cv=5).mean()\n",
    "\n",
    "\n",
    "res = minimize_scalar(nu_cross_val_score, bounds=(0, 1), options={\"xatol\":0.01})\n",
    "best_nu = res.x\n",
    "best_nu_score = -res.fun\n",
    "\n",
    "print(f'Для ядра rbf лучшее значение nu: {best_nu} с точностью: {best_nu_score}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кажется, это лучший результат, который мы можем получить от svc. Едем дальше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append((NuSVC(nu=best_nu), 'sklearn'))\n",
    "\n",
    "models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нейронные сети"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Базовая модель"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем в качестве модели многослойный перцептрон, для борьбы с переобучением\n",
    "воспользуемся слоями `Dropout`. Кроме того, добавим между слоями\n",
    "нормализацию по подвыборке для того, чтобы сгладить процесс обучения.\n",
    "\n",
    "В качестве функции активации выберем `leaky_relu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = pd.read_csv('inferenced.csv', index_col='track_id')\n",
    "selected.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dropout, Dense, BatchNormalization\n",
    "from keras.losses import CosineSimilarity\n",
    "\n",
    "clear_session()\n",
    "\n",
    "lr = 0.001\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Input(X_train.shape[1]))\n",
    "\n",
    "model.add(Dense(512, activation='leaky_relu', kernel_regularizer='l2'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Dense(128, activation='leaky_relu', kernel_regularizer='l2'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(64, activation='leaky_relu', kernel_regularizer='l2'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "              loss=CosineSimilarity(axis=1),\n",
    "              metrics=['categorical_accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_y_train = np.array(list(map(label2vec(n_classes), y_train)))\n",
    "nn_y_test = np.array(list(map(label2vec(n_classes), y_test)))\n",
    "nn_y_valid = np.array(list(map(label2vec(n_classes), y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = input()\n",
    "\n",
    "callbacks = [\n",
    "  TensorBoard(),\n",
    "  ModelCheckpoint(f'{run}/checkpoint/', save_best_only=True, save_weights_only=True, monitor='val_categorical_accuracy', verbose=1),\n",
    "  CSVLogger(\"logs.csv\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.learning_rate = 0.00005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, nn_y_train, validation_data=(X_valid, nn_y_valid), epochs=1000, callbacks=callbacks, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(f'{run}/checkpoint/')\n",
    "model.evaluate(X_test, nn_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append((model, 'keras'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение моделей, обученных на мета-данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in models:\n",
    "  model_type = entry[1]\n",
    "  model = entry[0]\n",
    "  if model_type == 'sklearn':\n",
    "    model.fit(X_train, y_train)\n",
    "    results = model.score(X_test, y_test)\n",
    "  else:\n",
    "    results = model.evaluate(X_test, nn_y_test)\n",
    "  print(f'Результат для {model.__class__.__name__}: {results}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сверточная нейронная сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loaders import MelImageDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(columns=selected.columns)\n",
    "valid = pd.DataFrame(columns=selected.columns)\n",
    "test = pd.DataFrame(columns=selected.columns)\n",
    "\n",
    "train_size = 0.8\n",
    "valid_size = 0.1\n",
    "\n",
    "for i in range(0, 8):\n",
    "  cur = selected[selected['track_genres'] == i]\n",
    "  \n",
    "  n = len(cur)\n",
    "  train = pd.concat([train, cur.iloc[:int(train_size * n)]])\n",
    "  valid = pd.concat([valid, cur.iloc[int(train_size * n):int((train_size + valid_size) * n)]])\n",
    "  test = pd.concat([test, cur.iloc[int((train_size + valid_size) * n):]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MelImageDataset(test, suffix='test',\n",
    "                               sr=44100, win_length=1380, \n",
    "                               hop_length=345, data_dir=DATA_DIR)\n",
    "val_dataset = MelImageDataset(valid, suffix='val',\n",
    "                              sr=44100, win_length=1380, \n",
    "                              hop_length=345, data_dir=DATA_DIR)\n",
    "train_dataset = MelImageDataset(train, suffix='train', \n",
    "                                sr=44100, win_length=1380, \n",
    "                                hop_length=345, data_dir=DATA_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_cache = None\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device('cuda')\n",
    "  empty_cache = torch.cuda.empty_cache\n",
    "elif torch.backends.mps.is_available():\n",
    "  device = torch.device(\"mps\")\n",
    "  empty_cache = torch.mps.empty_cache\n",
    "else:\n",
    "  device = torch.device(\"cpu\")\n",
    "  \n",
    "print(f\"Selected device: \\\"{device}\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "\n",
    "model = resnet18()\n",
    "\n",
    "torch.manual_seed(69)\n",
    "  \n",
    "model.fc = torch.nn.Sequential(\n",
    "  torch.nn.Dropout(p=0.2, inplace=True),\n",
    "  \n",
    "  torch.nn.Linear(in_features=512,\n",
    "                  out_features=256),\n",
    "  torch.nn.Dropout(p=0.2, inplace=True),\n",
    "  torch.nn.ReLU(inplace=True),\n",
    "  \n",
    "  torch.nn.BatchNorm1d(256),\n",
    "\n",
    "  torch.nn.Linear(in_features=256,\n",
    "                  out_features=128),\n",
    "  torch.nn.Dropout(p=0.2, inplace=True),\n",
    "  torch.nn.ReLU(inplace=True),\n",
    "  \n",
    "  torch.nn.BatchNorm1d(128),\n",
    "  \n",
    "  torch.nn.Linear(in_features=128,\n",
    "                  out_features=32),\n",
    "  torch.nn.Dropout(p=0.2, inplace=True),\n",
    "  \n",
    "  torch.nn.Linear(in_features=32,\n",
    "                  out_features=8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import save_state, restore_state\n",
    "from utils import TrainLogger\n",
    "                  \n",
    "from schedulers import DecayingCosineAnnealingLR\n",
    "                  \n",
    "if device.type != 'cpu':\n",
    "  empty_cache()\n",
    "\n",
    "initial_lr = 1e-6\n",
    "crit = torch.nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=initial_lr)\n",
    "\n",
    "model, opt, last_epoch, loss, acc, best_loss, best_acc, train_progress = \\\n",
    "    restore_state(model, opt, run)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "lr_scheduler = DecayingCosineAnnealingLR(opt, T_max=5,\n",
    "                                         eta_min=0.0001,\n",
    "                                         last_epoch=last_epoch)\n",
    "\n",
    "epochs = 100\n",
    "n_batches = len(train_loader)\n",
    "logger = TrainLogger(f\"logs/{run}\")\n",
    "\n",
    "for epoch in range(last_epoch + 1, epochs):\n",
    "  model.train()\n",
    "  \n",
    "  print(f'Epoch {epoch + 1}/{epochs}')\n",
    "  pbar = tf.keras.utils.Progbar(target=n_batches)\n",
    "  \n",
    "  lr = lr_scheduler.get_last_lr()[0]\n",
    "  correct = 0\n",
    "  samples = 0\n",
    "  for i, (inputs, targets) in enumerate(train_loader):\n",
    "    inputs = inputs.to(device)\n",
    "    \n",
    "    targets = targets.argmax(dim=1).to(device)\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    train_loss = crit(outputs, targets)\n",
    "    train_loss.backward()\n",
    "    \n",
    "    correct += int(torch.sum(outputs.argmax(dim=1) == targets))\n",
    "    samples += len(targets)\n",
    "    \n",
    "    opt.step()\n",
    "    pbar.update(i, values=[(\"loss\", train_loss.item()),\n",
    "                           (\"acc\", correct / samples),\n",
    "                           (\"lr\", lr)])\n",
    "    \n",
    "    train_loader.dataset.unload()\n",
    "    \n",
    "  # lr_scheduler.step()\n",
    "  model.eval()\n",
    "  \n",
    "  train_acc = correct / samples\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    correct = 0\n",
    "    samples = 0\n",
    "    for inputs, targets in val_loader:\n",
    "      inputs = inputs.to(device)\n",
    "      \n",
    "      targets = targets.argmax(dim=1)\n",
    "      targets = targets.to(device)\n",
    "      \n",
    "      outputs = model(inputs)\n",
    "      val_loss = crit(outputs, targets)\n",
    "      \n",
    "      correct += int(torch.sum(outputs.argmax(dim=1) == targets))\n",
    "      samples += len(targets)\n",
    "  \n",
    "  val_acc = correct / samples\n",
    "  val_loss = val_loss.item()\n",
    "  \n",
    "  logger.add(train_progress, loss=train_loss.item(), acc=train_acc,\n",
    "                             val_loss=val_loss, val_acc=val_acc,\n",
    "                             epoch=epoch, lr=lr)\n",
    "  \n",
    "  save_state(model, opt, epoch, train_progress, loss, acc, best_loss, best_acc, run)\n",
    "   \n",
    "  if val_loss < loss:\n",
    "    best_loss = val_loss\n",
    "    torch.save(model.state_dict(), f'{run}/best_loss.pt')\n",
    "    \n",
    "  if val_acc > acc:\n",
    "    best_acc = val_acc\n",
    "    torch.save(model.state_dict(), f'{run}/best_acc.pt')\n",
    "      \n",
    "  pbar.update(n_batches, values=[(\"val_loss\", val_loss), \n",
    "                                 (\"val_acc\", correct / samples)])\n",
    "  \n",
    "model.load_state_dict(f'{run}/best_acc.pt')\n",
    "torch.save(torch.jit.script(model), f'{run}/best_model_acc.pt')\n",
    "model.load_state_dict(f'{run}/best_loss.pt')\n",
    "torch.save(torch.jit.script(model), f'{run}/best_model_loss.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(probs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "e64c9a8690db34c99b15a1f7c3e93a32cbaa4232add629869dab3afba3bd6272"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
